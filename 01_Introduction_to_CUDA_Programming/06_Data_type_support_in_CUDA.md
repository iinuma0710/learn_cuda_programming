# 1.6 Data type support in CUDA
他のプロセッサ・アーキテクチャと同様，GPU も異なるタイプのメモリを持ち，それぞれに目的も異なっている．
詳細は2章で扱うが，サポートされている異なるデータ型を理解し，
パフォーマンスや精度に与える影響を知っておくことは重要である．
各プログラム言語の観点から，開発者がよく知っている標準的なデータ型は，CUDA プログラミングでも全てサポートされている．
様々なサイズを持つ標準的なデータ型 (char=1byte, float=4bytes, double=8bytes) 以外にも，
float2 や float4 のように，ベクトル型もサポートされている．

1，2，4，8，16バイトのサイズを持つデータ型の整列されたデータアクスは，
GPU のメモリから確実に1命令で呼び出すことができるため，データ型を自然にさせておくことが推奨されている．
整列されていないと，コンパイラは複数の命令を生成してしまい，
それが積み重なって，メモリや命令バスの非効率な使用につながる．
そのため，GPU メモリ上のデータが自然に整列されるような型を使うことが推奨されている．
この要件は，char，short，int，long，float，double，float2，float4 などの組み込みデータ型を使えば自動的に満たされる．

また，CUDA プログラミングでは，(C/C++ の)構造体やクラスのように，複雑なデータ構造もサポートしている．
複雑なデータ構造については，次のようにコンパイラに対して
データ整列要件を満たすようにする alignment specifier を使うことができる．

```c
struct __align__(16) {
    float r;
    float g;
    float b;
}
```

全ての GPU のコア数はそれぞれ限られているので，GPU によって FLOPS が異なる．
たとえば，Volta アーキテクチャを採用した Tesla V100 は，2560個の倍精度 FP64 コアを持ち，
単精度32ビットコアはその倍の数が実装されている．
アルゴリズムの要求する精度に基づいて正しいデータ型を使うことが必要不可欠であることは明白である．
アルゴリズムの一部を高精度で計算し，その他の部分をそれより低い精度で実行するようなアルゴリズムを，
異なるタイプのコアを使って開発しているとする．
これについては，後続の章でも扱う．
ここでは，GPU メモリには異なる階層があり，そのために，
正しいデータ型を使うのが重要だということを理解しておくことが大切である．